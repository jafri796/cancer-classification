training:
  batch_size: 32
  epochs: 50
  optimizer:
    type: Adam
    learning_rate: 0.001
  scheduler:
    type: StepLR
    step_size: 10
    gamma: 0.1
  seed: 42